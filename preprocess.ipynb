{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use the Agg backend which does not require a windowing system\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wandb\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from lightgbm import LGBMClassifier\n",
    "from pyHSICLasso import HSICLasso\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "from scipy.sparse import diags, eye\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, ElasticNet\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    return data\n",
    "\n",
    "def preprocess_dataset(data, test_size=0.2):\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "    data_rs = data\n",
    "    data_rs = pd.get_dummies(data_rs, columns=['histological.type'])\n",
    "    X = data_rs.drop(columns=['vital.status'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, data_rs['vital.status'], test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = load_data(filepath)\n",
    "    return preprocess_dataset(data)\n",
    "\n",
    "\n",
    "filepath = 'brca_data_w_subtypes.csv'\n",
    "X_train, X_test, y_train, y_test = load_and_preprocess_data(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class balance and Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HSIC_Lasso_custom():\n",
    "\n",
    "    def __init__(self, num_features=200):\n",
    "        self.num_features = num_features\n",
    "        self.hsic_lasso = None\n",
    "        self.selected_features = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        featname = list(np.arange(X.shape[1]))\n",
    "        self.hsic_lasso = HSICLasso()\n",
    "        self.hsic_lasso.input(X, y, featname=featname)\n",
    "        self.hsic_lasso.regression(num_feat=self.num_features, M=5, n_jobs=-1)\n",
    "        self.selected_features = self.hsic_lasso.get_index()\n",
    "        self.selected_features = np.array(self.selected_features, dtype=int)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.iloc[:, self.selected_features]\n",
    "    \n",
    "class Lasso_custom():\n",
    "        def __init__(self, alpha=0.1):\n",
    "            self.alpha = alpha\n",
    "            self.lasso = None\n",
    "            self.selected_features = None\n",
    "        \n",
    "        def fit(self, X, y):\n",
    "            X = np.array(X)\n",
    "            y = np.array(y)\n",
    "            self.lasso = Lasso(alpha=self.alpha)\n",
    "            self.lasso.fit(X, y)\n",
    "            self.selected_features = np.where(self.lasso.coef_ != 0)[0]\n",
    "        \n",
    "        def transform(self, X):\n",
    "            return X.iloc[:, self.selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block HSIC Lasso B = 20.\n",
      "M set to 5.\n",
      "Using Gaussian kernel for the features, Gaussian kernel for the outcomes.\n",
      "Block HSIC Lasso B = 20.\n",
      "M set to 5.\n",
      "Using Gaussian kernel for the features, Gaussian kernel for the outcomes.\n"
     ]
    }
   ],
   "source": [
    "## Class balance: SMOTE, RandomOverSampler\n",
    "## Feature selection: PCA, Lasso, ElasticNet, HSICLasso, SelectKBest, SelectFromLinearRegression, SelectFromRandomForest\n",
    "\n",
    "def apply_oversampler(oversampler, X_train, y_train):\n",
    "    if oversampler == 'SMOTE':\n",
    "        return SMOTE().fit_resample(X_train, y_train)\n",
    "    elif oversampler == 'RandomOverSampler':\n",
    "        return RandomOverSampler().fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        return X_train, y_train\n",
    "\n",
    "def apply_feature_selection(method, X_train, y_train, X_test):\n",
    "    # Initialize the transformer variable\n",
    "    transformer = None\n",
    "    \n",
    "    if method == 'PCA':\n",
    "        transformer = PCA(n_components=20).fit(X_train)\n",
    "    elif method == 'SelectKBest':\n",
    "        transformer = SelectKBest(k=2).fit(X_train, y_train)\n",
    "    elif method == 'SelectFromLinearRegression':\n",
    "        model = SelectFromModel(LinearRegression())\n",
    "        transformer = model.fit(X_train, y_train)\n",
    "    elif method == 'SelectFromRandomForest':\n",
    "        model = SelectFromModel(RandomForestRegressor())\n",
    "        transformer = model.fit(X_train, y_train)\n",
    "    elif method == 'ElasticNet':\n",
    "        model = SelectFromModel(ElasticNet())\n",
    "        transformer = model.fit(X_train, y_train)\n",
    "    elif method == 'Lasso':\n",
    "        model = Lasso_custom()\n",
    "        model.fit(X_train, y_train)\n",
    "        transformer = model\n",
    "    elif method == 'HSICLasso':\n",
    "        model = HSIC_Lasso_custom()\n",
    "        model.fit(X_train, y_train)\n",
    "        transformer = model\n",
    "    \n",
    "    # Transform both training and test datasets\n",
    "    if transformer:\n",
    "        X_train_transformed = transformer.transform(X_train)\n",
    "        X_test_transformed = transformer.transform(X_test)\n",
    "        return X_train_transformed, X_test_transformed, transformer\n",
    "    else:\n",
    "        return X_train, X_test, None\n",
    "\n",
    "def generate_datasets(X_train, y_train, X_test, y_test, oversamplers, feature_selection_methods):\n",
    "    datasets = {}\n",
    "    for oversampler in oversamplers:\n",
    "        X_train_res, y_train_res = apply_oversampler(oversampler, X_train, y_train)\n",
    "        for method in feature_selection_methods:\n",
    "            X_train_fs, X_test_fs, transformer = apply_feature_selection(method, X_train_res, y_train_res, X_test)\n",
    "            datasets[(oversampler, method)] = {'X_train': X_train_fs, 'y_train': y_train_res, 'X_test': X_test_fs, 'y_test': y_test, 'transformer': transformer}\n",
    "    return datasets\n",
    "\n",
    "\n",
    "oversamplers = ['SMOTE', 'RandomOverSampler']\n",
    "feature_selection_methods = ['PCA', 'Lasso', 'ElasticNet', 'HSICLasso', 'SelectKBest', 'SelectFromLinearRegression', 'SelectFromRandomForest']\n",
    "\n",
    "# Example usage:\n",
    "datasets_dict = generate_datasets(X_train, y_train, X_test, y_test, oversamplers, feature_selection_methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets.pkl', 'wb') as f:\n",
    "    pickle.dump(datasets_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
